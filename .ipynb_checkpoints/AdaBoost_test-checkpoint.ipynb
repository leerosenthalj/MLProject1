{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from IPython.display import HTML\n",
    "\n",
    "#Using tools provided to us for Problem Set 3.\n",
    "from boosting_helper import (\n",
    "    generate_dataset,\n",
    "    visualize_dataset,\n",
    "    gb_suite, ab_suite,\n",
    "    visualize_loss_curves_gb, visualize_loss_curves_ab,\n",
    "    animate_gb, animate_ab\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = np.loadtxt('training_data.txt', skiprows=1)\n",
    "test_data = np.loadtxt('test_data.txt', skiprows=1)\n",
    "\n",
    "X_train = training_data[:,1:]\n",
    "y_train = training_data[:,0]\n",
    "\n",
    "X_test = test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the AdaBoost class written for Problem Set 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdaBoost():\n",
    "    def __init__(self, n_clfs=100):\n",
    "        '''\n",
    "        Initialize the AdaBoost model.\n",
    "        Inputs:\n",
    "            n_clfs (default 100): Initializer for self.n_clfs.          \n",
    "        Attributes:\n",
    "            self.n_clfs: The number of DT weak classifiers.\n",
    "            self.coefs: A list of the AdaBoost coefficients.\n",
    "            self.clfs: A list of the DT weak classifiers, initialized as empty.\n",
    "        '''\n",
    "        self.n_clfs = n_clfs\n",
    "        self.coefs = []\n",
    "        self.clfs = []\n",
    "\n",
    "    def fit(self, X, Y, n_nodes=4):\n",
    "        '''\n",
    "        n_nodes: The max number of nodes that the DT weak classifiers are allowed to have.\n",
    "        Outputs:\n",
    "            A (N, T) shaped numpy array, where T is the number of iterations / DT weak classifiers,\n",
    "            such that the t^th column contains D_{t+1} (the dataset weights at iteration t+1).\n",
    "        '''\n",
    "    #==============================================\n",
    "    # TODO: implement the fit function.\n",
    "    #==============================================   \n",
    "        Ynew = np.copy(Y)\n",
    "        N = len(Ynew)\n",
    "        Ds = np.ones(N)/np.float(N) \n",
    "        weights = np.zeros((N, self.n_clfs))\n",
    "    \n",
    "        for i in np.arange(self.n_clfs):\n",
    "            clf = DecisionTreeClassifier(max_leaf_nodes=4)\n",
    "            #print(len(Y), len(Ds))\n",
    "            clf.fit(X, Ynew, Ds)\n",
    "            self.clfs.append(clf)\n",
    "            \n",
    "            error = np.sum(Ds[np.where(Ynew != clf.predict(X))])\n",
    "            alpha = 0.5*np.log((1 - error)/error)\n",
    "            \n",
    "            Ds = Ds*np.exp(-alpha*Ynew*clf.predict(X))\n",
    "            Ds /= np.sum(Ds)\n",
    "\n",
    "            self.coefs.append(alpha)\n",
    "            weights[:,i] = Ds\n",
    "\n",
    "        return weights\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predict on the given dataset.\n",
    "\n",
    "        Inputs:\n",
    "            X: A (N, D) shaped numpy array containing the data points.\n",
    "            \n",
    "        Outputs:\n",
    "            A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
    "            (Even though the labels are ints, we treat them as floats.)\n",
    "        '''\n",
    "        # Initialize predictions.\n",
    "        Y_pred = np.zeros(len(X))\n",
    "        \n",
    "        # Add predictions from each DT weak classifier.\n",
    "        for i, clf in enumerate(self.clfs):\n",
    "            Y_curr = self.coefs[i] * clf.predict(X)\n",
    "            Y_pred += Y_curr\n",
    "\n",
    "        # Return the sign of the predictions.\n",
    "        return np.sign(Y_pred)\n",
    "\n",
    "    def loss(self, X, Y):\n",
    "        \n",
    "        # Calculate the points where the predictions and the ground truths don't match.\n",
    "        Y_pred = self.predict(X)\n",
    "        misclassified = np.where(Y_pred != Y)[0]\n",
    "\n",
    "        # Return the fraction of such points.\n",
    "        return float(len(misclassified)) / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = AdaBoost()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model, D = ab_suite(AdaBoost, 500, X_train, Y_train, X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
